package mapreduce

import (
	"encoding/json"
	"os"
	"sort"
)

// doReduce does the job of a reduce worker: it reads the intermediate
// key/value pairs (produced by the map phase) for this task, sorts the
// intermediate key/value pairs by key, calls the user-defined reduce function
// (reduceF) for each key, and writes the output to disk.
func doReduce(
	jobName string, // the name of the whole MapReduce job
	reduceTaskNumber int, // which reduce task this is
	nMap int, // the number of map tasks that were run ("M" in the paper)
	reduceF func(key string, values []string) string,
) {

	// Read key value pairs from intermediate files generated by mapper.

	fileDecoders := make(map[string]*json.Decoder)
	for mapId := 0; mapId < nMap; mapId++ {
		mapFileName := reduceName(jobName, mapId, reduceTaskNumber)
		mapFile, err := os.Open(mapFileName)
		checkErr(err)
		defer mapFile.Close()

		decoder := json.NewDecoder(mapFile)
		fileDecoders[mapFileName] = decoder
	}

	// Decode key/value pairs from each intermediate files.
	keys := make([]string, 0)
	keyValueList := make(map[string][]string)

	for _, decoder := range fileDecoders {
		var kvpair KeyValue
		for decoder.More() {
			err := decoder.Decode(&kvpair)
			checkErr(err)

			keys = append(keys, kvpair.Key)
			keyValueList[kvpair.Key] = append(keyValueList[kvpair.Key], kvpair.Value)
		} 
	}

	// Sort by key.
	sort.Strings(keys)

	mergeFileName := mergeName(jobName, reduceTaskNumber)
	mergeFile, createErr:= os.Create(mergeFileName)
	checkErr(createErr)
	defer mergeFile.Close()
	mergeFileEncoder := json.NewEncoder(mergeFile)

	// Call user's reduce function and generate results
	for _, k := range keys {
		mergeFileEncoder.Encode(KeyValue{k, reduceF(k, keyValueList[k])})
	}
}
